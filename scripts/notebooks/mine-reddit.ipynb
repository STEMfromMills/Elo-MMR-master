{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting praw\n",
      "  Downloading praw-7.1.0-py3-none-any.whl (152 kB)\n",
      "\u001b[K     |████████████████████████████████| 152 kB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting update-checker>=0.17\n",
      "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
      "Collecting websocket-client>=0.54.0\n",
      "  Downloading websocket_client-0.57.0-py2.py3-none-any.whl (200 kB)\n",
      "\u001b[K     |████████████████████████████████| 200 kB 9.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting prawcore<2.0,>=1.3.0\n",
      "  Downloading prawcore-1.5.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: requests>=2.3.0 in /usr/lib/python3/dist-packages (from update-checker>=0.17->praw) (2.22.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from websocket-client>=0.54.0->praw) (1.14.0)\n",
      "Installing collected packages: update-checker, websocket-client, prawcore, praw\n",
      "Successfully installed praw-7.1.0 prawcore-1.5.0 update-checker-0.18.0 websocket-client-0.57.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<--------------Number of people that think Donald Trump has dismissed FBI Director James Comey 66 64223\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"8MguWY6Vv2iwDw\",  \n",
    "    client_secret=\"GyXPBkZaNZn1GT8o_K3lNXqx8mU\",\n",
    "    user_agent=\"Chrome:EloR Miner:v0.1 (by u/inutard)\")\n",
    "\n",
    "# From a glance at the daily top threads, gaming seems to be most popular\n",
    "# We'll mine from a specific subreddit to make sure theres some overlap in the user base\n",
    "thread_scores = []\n",
    "subreddit_name = \"SubredditSimulator\"\n",
    "# Each thread of O(1000) comments takes about 3min to process\n",
    "count = 0\n",
    "for submission in reddit.subreddit(\"SubredditSimulator\").top(limit=2000):\n",
    "    if count % 100 == 0:\n",
    "        print(submission.title, submission.num_comments, submission.score)\n",
    "    count += 1\n",
    "    submission.comments.replace_more(limit=None)\n",
    "    scores = []\n",
    "    seen = set()\n",
    "    for comment in submission.comments:\n",
    "        try:\n",
    "            scores.append((comment.score, comment.author.name))\n",
    "            seen.add(comment.author.name)\n",
    "        except:\n",
    "            # Likely deleted comments\n",
    "            pass\n",
    "        \n",
    "        # Include second-level and third-level comments too\n",
    "        for reply in comment.replies:\n",
    "            try:\n",
    "                if reply.author.name not in seen:\n",
    "                    scores.append((reply.score, reply.author.name))\n",
    "                    seen.add(reply.author.name)\n",
    "            except:\n",
    "                # Likely deleted comments\n",
    "                pass\n",
    "    thread_scores.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of unique commenters\n",
    "len(set(s[1] for score in thread_scores for s in score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequencies of top posters\n",
    "from collections import Counter\n",
    "C = Counter(list(s[1] for score in thread_scores for s in score))\n",
    "C.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of comments\n",
    "sum(len(s) for s in thread_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_scores[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "for tid, thread in enumerate(thread_scores):\n",
    "    data = {}\n",
    "    data['id'] = tid\n",
    "    data['name'] = \"To be filled.\"\n",
    "    data['time_seconds'] = 0\n",
    "    \n",
    "    standings = []\n",
    "    data['standings'] = standings\n",
    "    \n",
    "    names = set()\n",
    "    # Remove duplicate comments by consolidating votes\n",
    "    together = defaultdict(int)\n",
    "    for user in thread:\n",
    "        together[user[1]] += user[0]\n",
    "    thread = [(x[1], x[0]) for x in together.items()]\n",
    "    \n",
    "    thread = sorted(thread, reverse=True)\n",
    "    # Use -1 as placeholder value\n",
    "    lscore, lo, hi = -1, -1, -1\n",
    "    backlog = []\n",
    "    for user in thread:\n",
    "        if user[0] != lscore:\n",
    "            for name in backlog:\n",
    "                standings.append([name, lo, hi])\n",
    "            lo = hi = hi + 1\n",
    "            backlog = []\n",
    "        else:\n",
    "            hi += 1\n",
    "        backlog.append(user[1])\n",
    "        lscore = user[0]\n",
    "        \n",
    "    for name in backlog:\n",
    "        standings.append([name, lo, hi])\n",
    "    \n",
    "    with open('../cache/reddit/' + str(tid) + '.json', 'w') as out:\n",
    "        json.dump(data, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contest_ids = list(range(len(thread_scores)))\n",
    "with open('../data/reddit/contest_ids.json', 'w') as out:\n",
    "    out.write(str(contest_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = set(data[1] for thread in thread_scores for data in thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "karmalist = []\n",
    "for name in usernames:\n",
    "    user = reddit.redditor(name)\n",
    "    karmalist.append((user.comment_karma, user.name))\n",
    "    \n",
    "karmalist = sorted(karmalist, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/reddit/true_rankings.json', 'w') as out:\n",
    "    out.write(str(karmalist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "\n",
    "with open('../data/reddit/predicted_rankings.txt') as pfile:\n",
    "    plines = pfile.readlines()[12:]\n",
    "    joined_data = defaultdict(list)\n",
    "    for data in karmalist:\n",
    "        joined_data[data[1]].append(data[0])\n",
    "    for line in plines:\n",
    "        tokens = line.split()\n",
    "        rating = int(tokens[1].split('(')[0])\n",
    "        name = tokens[2]\n",
    "        joined_data[name].append(rating)\n",
    "        \n",
    "    # Basically we can delete any users that do not end in SS\n",
    "    for user in usernames:\n",
    "        if 'SS' != user[-2:]:\n",
    "            del joined_data[user]\n",
    "        \n",
    "    x, y = zip(*list(joined_data.values()))\n",
    "    plt.scatter(x, y, s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
